{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"TECHNICAL DOCUMENTATION IS UNDER CONTRUCTION Please refer to https://dodas-ts.github.io/dodas-templates/ for it Dynamic On Demand Analysis Service: DODAS Dynamic On Demand Analysis Service DODAS DODAS is a Platform as a Service tool built combining several solutions and products developed by the INDIGO-DataCloud H2020 project and now part of the EOSC-hub H2020 Project. DODAS allows to instantiate on-demand container-based clusters Apache Mesos Apache Mesos over any cloud with almost zero effort and with very limited knowledge of the underlying technical details DODAS provides the end user with all the support to deploy both HTCondor batch system and platforms for the Big Data analysis based on Spark, Hadoop etc. DODAS, as a Thematic Services in the context of EOSC-hub project, is financially supported by European Union\u2019s Horizon 2020 research and innovation programme, grant agreement RIA 777536. Contributing If you want to contribute to this documentation: create a branch upload your changes create a pull request Thanks! Render the page using Mkdocs You will need mkdocs installed on your machine. You can install it with pip: pip install mkdocs mkdocs-material To start a real time rendering of the doc just type: mkdocs serve The web page generated will be now update at each change you do on the local folder.","title":"Home"},{"location":"#dynamic-on-demand-analysis-service-dodas","text":"Dynamic On Demand Analysis Service DODAS DODAS is a Platform as a Service tool built combining several solutions and products developed by the INDIGO-DataCloud H2020 project and now part of the EOSC-hub H2020 Project. DODAS allows to instantiate on-demand container-based clusters Apache Mesos Apache Mesos over any cloud with almost zero effort and with very limited knowledge of the underlying technical details DODAS provides the end user with all the support to deploy both HTCondor batch system and platforms for the Big Data analysis based on Spark, Hadoop etc. DODAS, as a Thematic Services in the context of EOSC-hub project, is financially supported by European Union\u2019s Horizon 2020 research and innovation programme, grant agreement RIA 777536.","title":"Dynamic On Demand Analysis Service: DODAS"},{"location":"#contributing","text":"If you want to contribute to this documentation: create a branch upload your changes create a pull request Thanks!","title":"Contributing"},{"location":"#render-the-page-using-mkdocs","text":"You will need mkdocs installed on your machine. You can install it with pip: pip install mkdocs mkdocs-material To start a real time rendering of the doc just type: mkdocs serve The web page generated will be now update at each change you do on the local folder.","title":"Render the page using Mkdocs"},{"location":"contacts/","text":"Contact us DODAS Team provides two support channels, email and Slack channel. mailing list : send a message to the following list dodas-support@lists.infn.it slack channel : join us on Slack Channel","title":"Contact us"},{"location":"contacts/#contact-us","text":"DODAS Team provides two support channels, email and Slack channel. mailing list : send a message to the following list dodas-support@lists.infn.it slack channel : join us on Slack Channel","title":"Contact us"},{"location":"faq/","text":"WORK IN PROGRESS *","title":"WORK IN PROGRESS"},{"location":"faq/#work-in-progress","text":"*","title":"WORK IN PROGRESS"},{"location":"introduction/","text":"Introduction The mission of DODAS is to act as a cloud enabler for scientists seeking to easily exploit distributed and heterogeneous clouds to process, manipulate or generate data. Aiming to reduce the learning curve, as well as the operational cost of managing community specific services running on distributed cloud, DODAS completely automates the process of provisioning, creating, managing and accessing a pool of heterogeneous computing and storage resources. Within the EOSC-hub project DODAS - Thematic Service is providing both the PaaS core services and an Enabling Facility Cloud@CNAF and Cloud@ReCaS-Bari Cloud@CNAF and Cloud@ReCaS-Bari . Although DODAS PaaS core layer can be used to exploit any cloud , we foresee that a user might benefit of a freely accessible Enabling Facility where to test a customisation and/or simply try out how DODAS behaves etc. This guide provides not only an overview of the architecture and basic concepts behind DODAS, but also a comprehensive documentation for users willing to instantiate currently supported services: HTCondor batch system as a Service Big Data platform for ML as a Service either using the DODAS provided Enabling Facility or a user provided public Cloud as well as a private Cloud Amazon, Microsoft Azure, Open Telekom Cloud, etc Amazon, Microsoft Azure, Open Telekom Cloud, etc . Moreover this guide provides the reader guidelines on how to customise and extend the DODAS workflow. However, if you feel you are an impatient user, this is the section you are looking for. DODAS has been integrated by the Submission Infrastructure of Compact Muon Solenoid CMS CMS , one of the two bigger and general purposes experiments at LHC of CERN, as well as by the Alpha Magnetic Spectrometer AMS-02 AMS-02 computing environment.","title":"Introduction"},{"location":"introduction/#introduction","text":"The mission of DODAS is to act as a cloud enabler for scientists seeking to easily exploit distributed and heterogeneous clouds to process, manipulate or generate data. Aiming to reduce the learning curve, as well as the operational cost of managing community specific services running on distributed cloud, DODAS completely automates the process of provisioning, creating, managing and accessing a pool of heterogeneous computing and storage resources. Within the EOSC-hub project DODAS - Thematic Service is providing both the PaaS core services and an Enabling Facility Cloud@CNAF and Cloud@ReCaS-Bari Cloud@CNAF and Cloud@ReCaS-Bari . Although DODAS PaaS core layer can be used to exploit any cloud , we foresee that a user might benefit of a freely accessible Enabling Facility where to test a customisation and/or simply try out how DODAS behaves etc. This guide provides not only an overview of the architecture and basic concepts behind DODAS, but also a comprehensive documentation for users willing to instantiate currently supported services: HTCondor batch system as a Service Big Data platform for ML as a Service either using the DODAS provided Enabling Facility or a user provided public Cloud as well as a private Cloud Amazon, Microsoft Azure, Open Telekom Cloud, etc Amazon, Microsoft Azure, Open Telekom Cloud, etc . Moreover this guide provides the reader guidelines on how to customise and extend the DODAS workflow. However, if you feel you are an impatient user, this is the section you are looking for. DODAS has been integrated by the Submission Infrastructure of Compact Muon Solenoid CMS CMS , one of the two bigger and general purposes experiments at LHC of CERN, as well as by the Alpha Magnetic Spectrometer AMS-02 AMS-02 computing environment.","title":"Introduction"},{"location":"known-issues/","text":"WORK IN PROGRESS *","title":"WORK IN PROGRESS"},{"location":"known-issues/#work-in-progress","text":"*","title":"WORK IN PROGRESS"},{"location":"the-enabling-facility/","text":"The Enabling Facility DODAS is one of the 9 Thematic Services available in the context of EOSC-hub EU project. As such, the mission of DODAS is to provide support for the integration in to the PaaS core service of use cases and workflows required by those scientific communities seeking to exploit Cloud resources to accomplish their research activities. In order to make this integration processe more concrete the DODAS team provides not only the guidance for integrating the user community workflows, but also offers the possibility to test DODAS on a freely accessible cloud. This is the so called Enabling Facility . Data and compute resources of this Enabling Facility are offered by two distinct providers at INFN: Cloud@CNAF and ReCaS@Bari . Both of them are based on Openstack middleware. The Enabling Facility is freely accessible through DODAS PaaS core services, upon successful registration and authentication on https://dodas-iam.cloud.cnaf.infn.it/ .","title":"The Enabling Facility"},{"location":"the-enabling-facility/#the-enabling-facility","text":"DODAS is one of the 9 Thematic Services available in the context of EOSC-hub EU project. As such, the mission of DODAS is to provide support for the integration in to the PaaS core service of use cases and workflows required by those scientific communities seeking to exploit Cloud resources to accomplish their research activities. In order to make this integration processe more concrete the DODAS team provides not only the guidance for integrating the user community workflows, but also offers the possibility to test DODAS on a freely accessible cloud. This is the so called Enabling Facility . Data and compute resources of this Enabling Facility are offered by two distinct providers at INFN: Cloud@CNAF and ReCaS@Bari . Both of them are based on Openstack middleware. The Enabling Facility is freely accessible through DODAS PaaS core services, upon successful registration and authentication on https://dodas-iam.cloud.cnaf.infn.it/ .","title":"The Enabling Facility"},{"location":"troubleshooting/","text":"WORK IN PROGRESS","title":"WORK IN PROGRESS"},{"location":"troubleshooting/#work-in-progress","text":"","title":"WORK IN PROGRESS"},{"location":"getting-started/quick-start/","text":"Recipe for impatient users An impatient user seeking to try a DODAS deployment need to address the following 4 main steps: 1) Registration Register to the IAM-DODAS service by accessing the service here . You can use your IdP because IAM-DODAS supports eduGAIN identity federation. The first registration will require the approval from the DODAS admins. 2) Token Management Once your registration has been approved you can get your first DODAS token by using the recipe described and detailed here . As you can see there are two options currently supported although we consider the password flow deprecated. We strongly suggest the Device code Flow for all the reasons detailed. Note that for the Device code flow, you need to configure the following in the Client self-generated self-generated management dashboard : Access -> grant_types -> token . For a very impatient user: just download and execute this script . Please note The script requires that you have a client authorized for Device-Flow authorized for Device-Flow . You can either have your client self-service generated self-service generated or use a client provided by DODAS team. In both cases before running the script you need to know the following information: IAM_DEVICE_CODE_CLIENT_ID IAM_DEVICE_CODE_CLIENT_SECRET IAM_DEVICE_CODE_ENDPOINT IAM_TOKEN_ENDPOINT There will be a few steps to address. The script will guide you. You can set IAM_DEVICE_CODE_ENDPOINT=\" https://dodas-iam.cloud.cnaf.infn.it/devicecode \" and IAM_TOKEN_ENDPOINT=\" https://dodas-iam.cloud.cnaf.infn.it/token \" in the script. Client ID and secret are given when you create the Device code flow client as explained above . There are two kinds of token: access token : short-lived. This is used in the steps below to obtain resources. refresh token : long-lived. Used to refresh the access token without going through device authorization in browser. See for example this script . 3) Prepare your TOSCA template At that point you can checkout the already available TOSCA Templates here and pick the one you prefer. Otherwise just use the following simple TOSCA test to get a taste of the whole system just replace os:properties:image: Ubuntu\\_16.04 with an existing image just replace os:properties:image: Ubuntu\\_16.04 with an existing image : imports: - indigo_custom_types: https://raw.githubusercontent.com/indigo-dc/tosca-types/master/custom_types.yaml description: > Launch a VM Get IP and SSH credentials to access topology_template: node_templates: simple_node: type: tosca.nodes.indigo.Compute capabilities: endpoint: properties: network_name: PUBLIC ports: user_port: protocol: tcp source: 9000 other_port: protocol: tcp source: 9001 scalable: properties: count: 1 host: properties: instance_type: m1.small os: properties: image: Ubuntu_16.04 outputs: node_ip: value: { get_attribute: [ simple_node, public_address, 0 ] } node_creds: value: { get_attribute: [ simple_node, endpoint, credential, 0 ] } If you will choose a specific template not just the test once not just the test once you need to properly configure it. Configuration parameters should be documented on each TOSCA template. 4) Submit the TOSCA template Once configured, you can submit the TOSCA either to the PaaS Orchestrator or directly to IM. As a start, and if no complicated cloud configurations are needed, we recommend to start with direct submission to IM. Direct submission to IM The direct submission to IM can be done either via im-client or using the RESTful API. The extended guide provides all the recipes and information for installation and configuration of the CLI as well as the documentation of the REST APIs. However using the REST is highly suggested for the initial testing cause it guarantees a enormous flexibility, useful for a fast turnaround during tests. In any case the public endpoint is : https://im.cloud.cnaf.infn.it:8800/infrastructures And an example of REST based submission is curl -k -H 'Content-type: text/yaml' -H \"Authorization: id = ost; type = OpenStack; host = https://horizon.cloud.cnaf.infn.it:5000/v3; username = indigo-dc; password = $IAM_ACCESS_TOKEN; tenant = oidc; auth_version = 3.x_oidc_access_token; service_region = regionOne;\\nid = im; type = InfrastructureManager; token = $IAM_ACCESS_TOKEN\" -X POST http://im.cloud.cnaf.infn.it:8800/infrastructures --data-binary @\"<YOUR_TOSCA>.yaml\" And the expected output should be something like: HTTP/1.1 200 OKContent-Length: 86Content-Type: text/uri-listInfid: 9b044cce-6424-11e8-bad9-0242ac120003Date: Wed, 30 May 2018 16:15:11 GMT Server: Cheroot/6.3.1 http://im.cloud.cnaf.infn.it:8800/infrastructures/9b044cce-6424-11e8-bad9-0242ac120003 To submit to BARI, please use the following curl: curl -v -k -H 'Content-type: text/yaml' -H \"Authorization: id = os; type = OpenStack; host = https://cloud.recas.ba.infn.it:5000/; username = indigo-dc; password = $IAM_ACCESS_TOKEN; tenant = oidc; auth_version = 3.x_oidc_access_token; service_region = recas-cloud;\\nid = im; type = InfrastructureManager; token = $IAM_ACCESS_TOKEN\" -i -X POST https://im.cloud.cnaf.infn.it:443/infrastructures --data-binary \"@tosca-templates/dodas/CMS-HTCondor-dodas.yaml\" The above commands are based on POST to create the infrastructure described in the TOSCA template to create the infrastructure described in the TOSCA template , but you can also use GET to list to list or DELETE commands to manage the infrastructure that you have created. Please refer to the documentation linked here . Submission to the PaaS Orchestrator The Submission to the PaaS Orchestrator as well can be done both through the client and through the REST APIS. Here in this guide only the client based solution is taken into account. There are two steps: Installation the client called orchent following the recipe here . Once installed... Configuration and usage of the orchent client as described here . Be careful to the following notes: Despite the possibility to use the oidc-client we suggest to the ORCHENT_TOKEN based solution as described in the guide. Set the ORCHENT_URL env. variable using the endpoint as here below: export ORCHENT_URL=https://orchestrator.cloud.cnaf.infn.it/orchestrator The submission command should look like the following orchent depcreate <Your-TOSCA>.yaml '{}' the parenthesis '{}' can be used to pass the input parameter to the TOSCA. Although values can be filled in the template itself, the parenthesis must be left there otherwise you'll get an error. The output of the deployment creation depcreate <code class=\"codehilite\">depcreate</code> command will be something like the following Deployment [b8bdccf3-9be5-499f-aac2-664dc0726795]: status: CREATE_IN_PROGRESS creation time: 2018-06-16T15:58+0000 update time: 2018-06-16T15:58+0000 callback: status reason: task: NONE CloudProviderName: outputs: {} links: self [https://orchestrator.cloud.cnaf.infn.it/orchestrator/deployments/b8bdccf3-9be5-499f-aac2-664dc0726795] resources [https://orchestrator.cloud.cnaf.infn.it/orchestrator/deployments/b8bdccf3-9be5-499f-aac2-664dc0726795/resources] template [https://orchestrator.cloud.cnaf.infn.it/orchestrator/deployments/b8bdccf3-9be5-499f-aac2-664dc0726795/template] The above steps 1 to 3 are valid irrespective of which TOSCA template will be used. Templates available are HTCondor as batch system and Spark. Moreover there are Experiment specific customization, in particular CMS and AMS recipes. User can test all the recipes running on the freely accessible DODAS Enabling Facility .","title":"Recipe for impatient users"},{"location":"getting-started/quick-start/#recipe-for-impatient-users","text":"An impatient user seeking to try a DODAS deployment need to address the following 4 main steps:","title":"Recipe for impatient users"},{"location":"getting-started/quick-start/#141-registration","text":"Register to the IAM-DODAS service by accessing the service here . You can use your IdP because IAM-DODAS supports eduGAIN identity federation. The first registration will require the approval from the DODAS admins.","title":"1) Registration"},{"location":"getting-started/quick-start/#241-token-management","text":"Once your registration has been approved you can get your first DODAS token by using the recipe described and detailed here . As you can see there are two options currently supported although we consider the password flow deprecated. We strongly suggest the Device code Flow for all the reasons detailed. Note that for the Device code flow, you need to configure the following in the Client self-generated self-generated management dashboard : Access -> grant_types -> token . For a very impatient user: just download and execute this script . Please note The script requires that you have a client authorized for Device-Flow authorized for Device-Flow . You can either have your client self-service generated self-service generated or use a client provided by DODAS team. In both cases before running the script you need to know the following information: IAM_DEVICE_CODE_CLIENT_ID IAM_DEVICE_CODE_CLIENT_SECRET IAM_DEVICE_CODE_ENDPOINT IAM_TOKEN_ENDPOINT There will be a few steps to address. The script will guide you. You can set IAM_DEVICE_CODE_ENDPOINT=\" https://dodas-iam.cloud.cnaf.infn.it/devicecode \" and IAM_TOKEN_ENDPOINT=\" https://dodas-iam.cloud.cnaf.infn.it/token \" in the script. Client ID and secret are given when you create the Device code flow client as explained above . There are two kinds of token: access token : short-lived. This is used in the steps below to obtain resources. refresh token : long-lived. Used to refresh the access token without going through device authorization in browser. See for example this script .","title":"2) Token Management"},{"location":"getting-started/quick-start/#341-prepare-your-tosca-template","text":"At that point you can checkout the already available TOSCA Templates here and pick the one you prefer. Otherwise just use the following simple TOSCA test to get a taste of the whole system just replace os:properties:image: Ubuntu\\_16.04 with an existing image just replace os:properties:image: Ubuntu\\_16.04 with an existing image : imports: - indigo_custom_types: https://raw.githubusercontent.com/indigo-dc/tosca-types/master/custom_types.yaml description: > Launch a VM Get IP and SSH credentials to access topology_template: node_templates: simple_node: type: tosca.nodes.indigo.Compute capabilities: endpoint: properties: network_name: PUBLIC ports: user_port: protocol: tcp source: 9000 other_port: protocol: tcp source: 9001 scalable: properties: count: 1 host: properties: instance_type: m1.small os: properties: image: Ubuntu_16.04 outputs: node_ip: value: { get_attribute: [ simple_node, public_address, 0 ] } node_creds: value: { get_attribute: [ simple_node, endpoint, credential, 0 ] } If you will choose a specific template not just the test once not just the test once you need to properly configure it. Configuration parameters should be documented on each TOSCA template.","title":"3) Prepare your TOSCA template"},{"location":"getting-started/quick-start/#441-submit-the-tosca-template","text":"Once configured, you can submit the TOSCA either to the PaaS Orchestrator or directly to IM. As a start, and if no complicated cloud configurations are needed, we recommend to start with direct submission to IM.","title":"4) Submit the TOSCA template"},{"location":"getting-started/quick-start/#direct-submission-to-im","text":"The direct submission to IM can be done either via im-client or using the RESTful API. The extended guide provides all the recipes and information for installation and configuration of the CLI as well as the documentation of the REST APIs. However using the REST is highly suggested for the initial testing cause it guarantees a enormous flexibility, useful for a fast turnaround during tests. In any case the public endpoint is : https://im.cloud.cnaf.infn.it:8800/infrastructures And an example of REST based submission is curl -k -H 'Content-type: text/yaml' -H \"Authorization: id = ost; type = OpenStack; host = https://horizon.cloud.cnaf.infn.it:5000/v3; username = indigo-dc; password = $IAM_ACCESS_TOKEN; tenant = oidc; auth_version = 3.x_oidc_access_token; service_region = regionOne;\\nid = im; type = InfrastructureManager; token = $IAM_ACCESS_TOKEN\" -X POST http://im.cloud.cnaf.infn.it:8800/infrastructures --data-binary @\"<YOUR_TOSCA>.yaml\" And the expected output should be something like: HTTP/1.1 200 OKContent-Length: 86Content-Type: text/uri-listInfid: 9b044cce-6424-11e8-bad9-0242ac120003Date: Wed, 30 May 2018 16:15:11 GMT Server: Cheroot/6.3.1 http://im.cloud.cnaf.infn.it:8800/infrastructures/9b044cce-6424-11e8-bad9-0242ac120003 To submit to BARI, please use the following curl: curl -v -k -H 'Content-type: text/yaml' -H \"Authorization: id = os; type = OpenStack; host = https://cloud.recas.ba.infn.it:5000/; username = indigo-dc; password = $IAM_ACCESS_TOKEN; tenant = oidc; auth_version = 3.x_oidc_access_token; service_region = recas-cloud;\\nid = im; type = InfrastructureManager; token = $IAM_ACCESS_TOKEN\" -i -X POST https://im.cloud.cnaf.infn.it:443/infrastructures --data-binary \"@tosca-templates/dodas/CMS-HTCondor-dodas.yaml\" The above commands are based on POST to create the infrastructure described in the TOSCA template to create the infrastructure described in the TOSCA template , but you can also use GET to list to list or DELETE commands to manage the infrastructure that you have created. Please refer to the documentation linked here .","title":"Direct submission to IM"},{"location":"getting-started/quick-start/#submission-to-the-paas-orchestrator","text":"The Submission to the PaaS Orchestrator as well can be done both through the client and through the REST APIS. Here in this guide only the client based solution is taken into account. There are two steps: Installation the client called orchent following the recipe here . Once installed... Configuration and usage of the orchent client as described here . Be careful to the following notes: Despite the possibility to use the oidc-client we suggest to the ORCHENT_TOKEN based solution as described in the guide. Set the ORCHENT_URL env. variable using the endpoint as here below: export ORCHENT_URL=https://orchestrator.cloud.cnaf.infn.it/orchestrator The submission command should look like the following orchent depcreate <Your-TOSCA>.yaml '{}' the parenthesis '{}' can be used to pass the input parameter to the TOSCA. Although values can be filled in the template itself, the parenthesis must be left there otherwise you'll get an error. The output of the deployment creation depcreate <code class=\"codehilite\">depcreate</code> command will be something like the following Deployment [b8bdccf3-9be5-499f-aac2-664dc0726795]: status: CREATE_IN_PROGRESS creation time: 2018-06-16T15:58+0000 update time: 2018-06-16T15:58+0000 callback: status reason: task: NONE CloudProviderName: outputs: {} links: self [https://orchestrator.cloud.cnaf.infn.it/orchestrator/deployments/b8bdccf3-9be5-499f-aac2-664dc0726795] resources [https://orchestrator.cloud.cnaf.infn.it/orchestrator/deployments/b8bdccf3-9be5-499f-aac2-664dc0726795/resources] template [https://orchestrator.cloud.cnaf.infn.it/orchestrator/deployments/b8bdccf3-9be5-499f-aac2-664dc0726795/template] The above steps 1 to 3 are valid irrespective of which TOSCA template will be used. Templates available are HTCondor as batch system and Spark. Moreover there are Experiment specific customization, in particular CMS and AMS recipes. User can test all the recipes running on the freely accessible DODAS Enabling Facility .","title":"Submission to the PaaS Orchestrator"},{"location":"getting-started/before-starting/dodas-client-installation/","text":"WORK IN PROGRESS","title":"WORK IN PROGRESS"},{"location":"getting-started/before-starting/dodas-client-installation/#work-in-progress","text":"","title":"WORK IN PROGRESS"},{"location":"getting-started/before-starting/providers/aws/","text":"WORK IN PROGRESS","title":"WORK IN PROGRESS"},{"location":"getting-started/before-starting/providers/aws/#work-in-progress","text":"","title":"WORK IN PROGRESS"},{"location":"getting-started/before-starting/providers/azure/","text":"WORK IN PROGRESS","title":"WORK IN PROGRESS"},{"location":"getting-started/before-starting/providers/azure/#work-in-progress","text":"","title":"WORK IN PROGRESS"},{"location":"getting-started/before-starting/providers/bare/","text":"WORK IN PROGRESS","title":"WORK IN PROGRESS"},{"location":"getting-started/before-starting/providers/bare/#work-in-progress","text":"","title":"WORK IN PROGRESS"},{"location":"getting-started/before-starting/providers/gcp/","text":"WORK IN PROGRESS","title":"WORK IN PROGRESS"},{"location":"getting-started/before-starting/providers/gcp/#work-in-progress","text":"","title":"WORK IN PROGRESS"},{"location":"getting-started/before-starting/providers/os/","text":"WORK IN PROGRESS","title":"WORK IN PROGRESS"},{"location":"getting-started/before-starting/providers/os/#work-in-progress","text":"","title":"WORK IN PROGRESS"},{"location":"getting-started/tutorials/ams-recipe/","text":"WORK IN PROGRESS","title":"HTCondor cluster for AMS"},{"location":"getting-started/tutorials/ams-recipe/#work-in-progress","text":"","title":"WORK IN PROGRESS"},{"location":"getting-started/tutorials/cms-recipe/","text":"HTCondor CMS Recipe The DODAS workflow implemented for CMS has been designed in order to generate an ephemeral Tier* WLCG compliant. Prerequisites In the basic implementation has been built on the following assumptions There is no Computing Element . Worker nodes HTCondor startd processes HTCondor startd processes start up as a docker container over Mesos cluster, and auto-join the HTCondor Global-Pool of CMS Data I/O is meant to rely on AAA xrootd read rule although there is not technical limitation preventing the usage of local storages. stage-out relies on a Tier site of CMS, e.g. INFN relies on TI_IT_CNAF. The result is something like this in the site local config url=\"trivialcatalog_file:/cvmfs/cms.cern.ch/SITECONF/T1_IT_CNAF/PhEDEx/storage.xml?protocol=srmv2\"/> This imply to accomplish with the following pre-requisites: Requires Submission Infrastructure SI SI L2s authorization for Global-Pool access. In order to being authorized you must belong to the CMS Collaboration and provide a DN and CMS Site Name. SI will use these info to define the proper mapping in the match-maker. Get a DN from X.509 Certificate you can retrieve from the Token Translation Service . 1. Click to request a x509. 2. A pop-up window will allow you to download the certificate PEM file. At that point you should run openssl x509 -noout -in <certificate.pem> -subject 3. and you will obtain something like subject= /C=IT/O=CLOUD@CNAF/CN=xxxxxxx@dodas-iam Define a name for your ephemeral CMS Site: e.g. T3_XX_Opportunistic_KK If you want to be visible in the Dashboard this is ONLY true for the old-fashioned [Dashboard](http://dashboard.cern.ch/cms/) this is ONLY true for the old-fashioned [Dashboard](http://dashboard.cern.ch/cms/) you need to notify the dashboard support team informing that you need the following mapping among Site Name and SyncCE Site Name == T3_XX_Opportunistic_KK SyncCE == T3_XX_Opportunistic_KK NOTE : This is needed because DODAS does not deploy a cluster which relies on a Computing Element. You need to provide a job id to the CERN monitoring team. Long Running Services Once done all of this, you should be able to get this TOSCA template and configure everything as described in the template itself. The CMS template deploys the following services and components: - squid proxy - proxy cache - worker node HTCondor startd HTCondor startd - cvmfs - cvmfs-check app - CMS Trivial File Catalogue Docker image files are available here . Launching a DODAS instance of HTCondor for CMS This assume you are now familiar with following steps: how to GET a token from IAM-DODAS how to submit a TOSCA template either with PaaS orchestrator or Infrastructure Manager either with PaaS orchestrator or Infrastructure Manager You can get the basic CMS TOSCA template from here and submit it after a proper configuration. There input parameters to be set are explained below. THere are 3 sections and these are the mandatory parameters. For advanced usage there is more to be configured. Marathon and Mesos related configuration parameters marathon_username : Admin username for Marathon GUI marathon_password : Admin password for for Marathon GUI mesos_username : Admin username for Mesos GUI mesos_password : Admin password for Mesos GUI number_of_masters : num_cpus_master : mem_size_master : number_of_slaves : num_cpus_slave : mem_size_slave: number_of_lbs : num_cpus_lb : mem_size_lb : server_image : Image for the Virtual Machine to be used. NOTE all the recipes are validated for Ubuntu Xenial. IAM related configurations to enable the OIDC to X.509 certificate translation iam_token : The token string obtained as explained here Iam_client_id : This must be provided once once by DODAS admins iam_client_secret : This must be provided once once by DODAS admins CMS specific configurations cms_local_site : This is a name of the format T3_XX_Opportunistic_KK. You decide this as explained here . cms_stageoutsite : This must be either an already existing T\u00bd/3, or a new site you will register in the CMS computing system. cms_stageoutprotocol : this is the protocol you want to use, to be set accordingly with one of the options supported by the SITECONF related to the cms_stageoutsite. Once the cluster has been created you should be able to access the Marathon and Mesos GUIs for management, debugging etc. The very last step of the deployment is the start-up HTCondor startd process. If no errors are encountered the startds should join the HTCondor global pool automatically, and thus if matching happens HTCondor start executing payloads. At that point, most probably, you would like to submit some jobs with proper configuration to allow the matching. Submitting CRAB jobs for DODAS CMS Site In order to submit CRAB jobs with proper classad parameters which guarantee the matching, you need to add this extra line in the configuration file of CRAB: config.Debug.extraJDL = [ '+DESIRED_Sites=\"T3_XX_XY_KK\"','+JOB_CMSSite=\"T3_XX_XY_KK\"','+AccountingGroup=\"highprio.<YOUR_LXPLUS_LOGIN>\"' ] There is no any other change you need to do. Finally there is a basic Elastic Search monitoring system which can be used and extended to cope with user specific needs. This is detailed here .","title":"HTCondor cluster for CMS"},{"location":"getting-started/tutorials/cms-recipe/#htcondor-cms-recipe","text":"The DODAS workflow implemented for CMS has been designed in order to generate an ephemeral Tier* WLCG compliant.","title":"HTCondor CMS Recipe"},{"location":"getting-started/tutorials/cms-recipe/#prerequisites","text":"In the basic implementation has been built on the following assumptions There is no Computing Element . Worker nodes HTCondor startd processes HTCondor startd processes start up as a docker container over Mesos cluster, and auto-join the HTCondor Global-Pool of CMS Data I/O is meant to rely on AAA xrootd read rule although there is not technical limitation preventing the usage of local storages. stage-out relies on a Tier site of CMS, e.g. INFN relies on TI_IT_CNAF. The result is something like this in the site local config url=\"trivialcatalog_file:/cvmfs/cms.cern.ch/SITECONF/T1_IT_CNAF/PhEDEx/storage.xml?protocol=srmv2\"/> This imply to accomplish with the following pre-requisites: Requires Submission Infrastructure SI SI L2s authorization for Global-Pool access. In order to being authorized you must belong to the CMS Collaboration and provide a DN and CMS Site Name. SI will use these info to define the proper mapping in the match-maker. Get a DN from X.509 Certificate you can retrieve from the Token Translation Service . 1. Click to request a x509. 2. A pop-up window will allow you to download the certificate PEM file. At that point you should run openssl x509 -noout -in <certificate.pem> -subject 3. and you will obtain something like subject= /C=IT/O=CLOUD@CNAF/CN=xxxxxxx@dodas-iam Define a name for your ephemeral CMS Site: e.g. T3_XX_Opportunistic_KK If you want to be visible in the Dashboard this is ONLY true for the old-fashioned [Dashboard](http://dashboard.cern.ch/cms/) this is ONLY true for the old-fashioned [Dashboard](http://dashboard.cern.ch/cms/) you need to notify the dashboard support team informing that you need the following mapping among Site Name and SyncCE Site Name == T3_XX_Opportunistic_KK SyncCE == T3_XX_Opportunistic_KK NOTE : This is needed because DODAS does not deploy a cluster which relies on a Computing Element. You need to provide a job id to the CERN monitoring team.","title":"Prerequisites"},{"location":"getting-started/tutorials/cms-recipe/#long-running-services","text":"Once done all of this, you should be able to get this TOSCA template and configure everything as described in the template itself. The CMS template deploys the following services and components: - squid proxy - proxy cache - worker node HTCondor startd HTCondor startd - cvmfs - cvmfs-check app - CMS Trivial File Catalogue Docker image files are available here .","title":"Long Running Services"},{"location":"getting-started/tutorials/cms-recipe/#launching-a-dodas-instance-of-htcondor-for-cms","text":"This assume you are now familiar with following steps: how to GET a token from IAM-DODAS how to submit a TOSCA template either with PaaS orchestrator or Infrastructure Manager either with PaaS orchestrator or Infrastructure Manager You can get the basic CMS TOSCA template from here and submit it after a proper configuration. There input parameters to be set are explained below. THere are 3 sections and these are the mandatory parameters. For advanced usage there is more to be configured. Marathon and Mesos related configuration parameters marathon_username : Admin username for Marathon GUI marathon_password : Admin password for for Marathon GUI mesos_username : Admin username for Mesos GUI mesos_password : Admin password for Mesos GUI number_of_masters : num_cpus_master : mem_size_master : number_of_slaves : num_cpus_slave : mem_size_slave: number_of_lbs : num_cpus_lb : mem_size_lb : server_image : Image for the Virtual Machine to be used. NOTE all the recipes are validated for Ubuntu Xenial. IAM related configurations to enable the OIDC to X.509 certificate translation iam_token : The token string obtained as explained here Iam_client_id : This must be provided once once by DODAS admins iam_client_secret : This must be provided once once by DODAS admins CMS specific configurations cms_local_site : This is a name of the format T3_XX_Opportunistic_KK. You decide this as explained here . cms_stageoutsite : This must be either an already existing T\u00bd/3, or a new site you will register in the CMS computing system. cms_stageoutprotocol : this is the protocol you want to use, to be set accordingly with one of the options supported by the SITECONF related to the cms_stageoutsite. Once the cluster has been created you should be able to access the Marathon and Mesos GUIs for management, debugging etc. The very last step of the deployment is the start-up HTCondor startd process. If no errors are encountered the startds should join the HTCondor global pool automatically, and thus if matching happens HTCondor start executing payloads. At that point, most probably, you would like to submit some jobs with proper configuration to allow the matching.","title":"Launching a DODAS instance of HTCondor for CMS"},{"location":"getting-started/tutorials/cms-recipe/#submitting-crab-jobs-for-dodas-cms-site","text":"In order to submit CRAB jobs with proper classad parameters which guarantee the matching, you need to add this extra line in the configuration file of CRAB: config.Debug.extraJDL = [ '+DESIRED_Sites=\"T3_XX_XY_KK\"','+JOB_CMSSite=\"T3_XX_XY_KK\"','+AccountingGroup=\"highprio.<YOUR_LXPLUS_LOGIN>\"' ] There is no any other change you need to do. Finally there is a basic Elastic Search monitoring system which can be used and extended to cope with user specific needs. This is detailed here .","title":"Submitting CRAB jobs for DODAS CMS Site"},{"location":"getting-started/tutorials/htc-recipe/","text":"WORK IN PROGRESS","title":"WORK IN PROGRESS"},{"location":"getting-started/tutorials/htc-recipe/#work-in-progress","text":"","title":"WORK IN PROGRESS"},{"location":"getting-started/tutorials/spark-recipe/","text":"WORK IN PROGRESS","title":"WORK IN PROGRESS"},{"location":"getting-started/tutorials/spark-recipe/#work-in-progress","text":"","title":"WORK IN PROGRESS"},{"location":"getting-started/tutorials/xcache-recipe/","text":"WORK IN PROGRESS","title":"WORK IN PROGRESS"},{"location":"getting-started/tutorials/xcache-recipe/#work-in-progress","text":"","title":"WORK IN PROGRESS"},{"location":"overview/architecture/","text":"WORK IN PROGRESS Components Admins authenticate with the Infrastructure Manager using either username and password or a IAM access token IM uses the TOSCA template provided by the admin to deploy: a k8s cluster using the k8s ansible role here also k3s availabel here one or more helm charts on top of it using the helm install ansible role here kubectl create of any manifest is also supported by an ansible role any other action supported or integrated into a tosca node type","title":"Architecture"},{"location":"overview/architecture/#work-in-progress","text":"","title":"WORK IN PROGRESS"},{"location":"overview/architecture/#components","text":"Admins authenticate with the Infrastructure Manager using either username and password or a IAM access token IM uses the TOSCA template provided by the admin to deploy: a k8s cluster using the k8s ansible role here also k3s availabel here one or more helm charts on top of it using the helm install ansible role here kubectl create of any manifest is also supported by an ansible role any other action supported or integrated into a tosca node type","title":"Components"},{"location":"overview/general-idea/","text":"DODAS: How it is made DODAS Architecture: Basic Concepts DODAS has a highly modular architecture and the workflows are highly customisable. This is extremely valuable for a user because it is a key to the possibility of extending the already provided configuration with anything the user might need from software dependencies up to the integration of external services passing through the user tailored code management from software dependencies up to the integration of external services passing through the user tailored code management . This kind of flexibility is achieved thanks to the modularity of the overall system which is shortly described below. The major sub-services composing DODAS are: the INDIGO Identity and Access Management IAM IAM and Token Translation Service TTS TTS , PaaS Orchestrator and Infrastructure Manager IM IM . Those composition of services represents the so-called PaaS Core Services of DODAS. IAM is the OpenidConnect Authorization Server which has the crucial role to authenticate the user and to provide her/him with a OIDC token which in turn is used to delegate service to act on behalf of the user itself. While the user must register to the IAM-DODAS instance, a federated system supporting eduGAIN, the PaaS Orchestrator and/or IM are responsible to take care of the user request in form of a TOSCA template in form of a TOSCA template and prepare a cluster for containers orchestration over the IaaS . DODAS relies on Mesos for the container orchestration. The container orchestrator is meant as a layer where the end-users service can be executed. Regarding the PaaS Orchestrator and IM, both have the role of abstracting the underlying IaaSes and both of them support the same TOSCA language for input data description. There are differences among the two, and there are additional features with respect to the abstraction with respect to the abstraction which are only supported by the PaaS Orchestrator. Concrete examples are: A user needs to access a multi cloud environment, which in principle could be a combination of both public and private provider hybrid model hybrid model , in this case the Orchestrator guarantee a transparent management of the underlying IaaSes A user needs support to the elasticity meant as an elastic extension of cluster based on load, the PaaS Orchestrator provides the proper support thanks to the integration with Clues . On the other hand it is worth mentioning that using your own public or private cloud through the orchestrator requires some registration steps , while the IM does not require any resource registration. A high level view from the end user perspectives DODAS from the user perspective is a service aiming at enabling an easy solution for the creation of a complex setup for a computational environment on any cloud based environment. In other words, DODAS aim is to make the process of generating intricate setups as easy as it is today creating a virtual machine on any IaaS: a one-click solution. The summary of the major added values of DODAS for a scientist is: To provide a complete abstraction of the underlying clouds To automate the virtual hardware provisioning and configuration To provide a cluster platform with a high level of self-healing To guarantee setup and service customization to cope with specific requirements More concretely \"a complex setup\" in this context means a container orchestrator e.g. Mesos e.g. Mesos on top of which there could be any framework which in turn manages the user service. The user service can be anything in principle, however DODAS provides two principal baselines ready to be used and to be possibly extended: a HTCondor batch system and a Spark cluster. Dealing with DODAS for a user means to configure and submit a TOSCA template. Several templates have already been developed, one per supported use case see [this section](../getting-started/) for further details see [this section](../getting-started/) for further details but, of course, it is worth to remark that the key value is that you can either extend any of them or create your own. For the sake of completeness the very first step before developing and / or using existing templates is to register, and this must be done through the IAM-DODAS service. Except the registration step there is nothing else which represents a pre-requisite DODAS specific. There are, of course, pre-requisites both if you are about to use the CMS and AMS implementation of DODAS as well as if you are supposed to External IaaS read as some cloud different from the provided [Enabling Facility](../../the-enabling-facility.md) read as some cloud different from the provided [Enabling Facility](../../the-enabling-facility.md) , as explained here .","title":"The general idea"},{"location":"overview/general-idea/#dodas-how-it-is-made","text":"","title":"DODAS: How it is made"},{"location":"overview/general-idea/#dodas-architecture-basic-concepts","text":"DODAS has a highly modular architecture and the workflows are highly customisable. This is extremely valuable for a user because it is a key to the possibility of extending the already provided configuration with anything the user might need from software dependencies up to the integration of external services passing through the user tailored code management from software dependencies up to the integration of external services passing through the user tailored code management . This kind of flexibility is achieved thanks to the modularity of the overall system which is shortly described below. The major sub-services composing DODAS are: the INDIGO Identity and Access Management IAM IAM and Token Translation Service TTS TTS , PaaS Orchestrator and Infrastructure Manager IM IM . Those composition of services represents the so-called PaaS Core Services of DODAS. IAM is the OpenidConnect Authorization Server which has the crucial role to authenticate the user and to provide her/him with a OIDC token which in turn is used to delegate service to act on behalf of the user itself. While the user must register to the IAM-DODAS instance, a federated system supporting eduGAIN, the PaaS Orchestrator and/or IM are responsible to take care of the user request in form of a TOSCA template in form of a TOSCA template and prepare a cluster for containers orchestration over the IaaS . DODAS relies on Mesos for the container orchestration. The container orchestrator is meant as a layer where the end-users service can be executed. Regarding the PaaS Orchestrator and IM, both have the role of abstracting the underlying IaaSes and both of them support the same TOSCA language for input data description. There are differences among the two, and there are additional features with respect to the abstraction with respect to the abstraction which are only supported by the PaaS Orchestrator. Concrete examples are: A user needs to access a multi cloud environment, which in principle could be a combination of both public and private provider hybrid model hybrid model , in this case the Orchestrator guarantee a transparent management of the underlying IaaSes A user needs support to the elasticity meant as an elastic extension of cluster based on load, the PaaS Orchestrator provides the proper support thanks to the integration with Clues . On the other hand it is worth mentioning that using your own public or private cloud through the orchestrator requires some registration steps , while the IM does not require any resource registration.","title":"DODAS Architecture: Basic Concepts"},{"location":"overview/general-idea/#a-high-level-view-from-the-end-user-perspectives","text":"DODAS from the user perspective is a service aiming at enabling an easy solution for the creation of a complex setup for a computational environment on any cloud based environment. In other words, DODAS aim is to make the process of generating intricate setups as easy as it is today creating a virtual machine on any IaaS: a one-click solution. The summary of the major added values of DODAS for a scientist is: To provide a complete abstraction of the underlying clouds To automate the virtual hardware provisioning and configuration To provide a cluster platform with a high level of self-healing To guarantee setup and service customization to cope with specific requirements More concretely \"a complex setup\" in this context means a container orchestrator e.g. Mesos e.g. Mesos on top of which there could be any framework which in turn manages the user service. The user service can be anything in principle, however DODAS provides two principal baselines ready to be used and to be possibly extended: a HTCondor batch system and a Spark cluster. Dealing with DODAS for a user means to configure and submit a TOSCA template. Several templates have already been developed, one per supported use case see [this section](../getting-started/) for further details see [this section](../getting-started/) for further details but, of course, it is worth to remark that the key value is that you can either extend any of them or create your own. For the sake of completeness the very first step before developing and / or using existing templates is to register, and this must be done through the IAM-DODAS service. Except the registration step there is nothing else which represents a pre-requisite DODAS specific. There are, of course, pre-requisites both if you are about to use the CMS and AMS implementation of DODAS as well as if you are supposed to External IaaS read as some cloud different from the provided [Enabling Facility](../../the-enabling-facility.md) read as some cloud different from the provided [Enabling Facility](../../the-enabling-facility.md) , as explained here .","title":"A high level view from the end user perspectives"},{"location":"overview/workflow/","text":"WORK IN PROGRESS","title":"WORK IN PROGRESS"},{"location":"overview/workflow/#work-in-progress","text":"","title":"WORK IN PROGRESS"},{"location":"supported-solutions/ams/","text":"WORK IN PROGRESS","title":"WORK IN PROGRESS"},{"location":"supported-solutions/ams/#work-in-progress","text":"","title":"WORK IN PROGRESS"},{"location":"supported-solutions/cms/","text":"WORK IN PROGRESS","title":"WORK IN PROGRESS"},{"location":"supported-solutions/cms/#work-in-progress","text":"","title":"WORK IN PROGRESS"},{"location":"supported-solutions/htc/","text":"WORK IN PROGRESS","title":"WORK IN PROGRESS"},{"location":"supported-solutions/htc/#work-in-progress","text":"","title":"WORK IN PROGRESS"},{"location":"supported-solutions/spark/","text":"WORK IN PROGRESS","title":"WORK IN PROGRESS"},{"location":"supported-solutions/spark/#work-in-progress","text":"","title":"WORK IN PROGRESS"},{"location":"supported-solutions/xcache/","text":"WORK IN PROGRESS","title":"WORK IN PROGRESS"},{"location":"supported-solutions/xcache/#work-in-progress","text":"","title":"WORK IN PROGRESS"}]}